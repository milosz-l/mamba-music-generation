name: mamba
model_dimension: 1024
n_layer: 48
vocab_size: 30000
rms_norm: True
residual_in_fp32: True
fused_add_norm: True
pad_vocab_size_multiple:  8
tie_embeddings: True
ssm_config:
  d_conv: 4
  d_state: 16
  expand: 2
